# -*- coding: utf-8 -*-
"""Credict Card Fraud Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11sMF-RGlDjVFezh74-adWbMiBdm5IoB6
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# Load Dataset
data = pd.read_csv('/content/drive/MyDrive/GrowthLink/creditcard.csv')

# Exploratory Data Analysis
print("Dataset Shape:", data.shape)
print("Missing Values:", data.isnull().sum().sum())
print("Class Distribution:\n", data['Class'].value_counts())

# Handling Class Imbalance using SMOTE
X = data.drop(columns=['Class'])
y = data['Class']
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

smote = SMOTE(sampling_strategy=0.5, random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_scaled, y)
print("Resampled Class Distribution:\n", pd.Series(y_resampled).value_counts())

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Model Training & Evaluation
models = {
    "Logistic Regression": LogisticRegression(),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss')
}

for name, model in models.items():
    print(f"Training {name}...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"{name} Classification Report:\n", classification_report(y_test, y_pred))
    print(f"{name} ROC-AUC Score:", roc_auc_score(y_test, y_pred))
    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
    plt.title(f"{name} Confusion Matrix")
    plt.show()

# Example: Adding a missing feature with a default value (adjust accordingly)
new_transaction.append(0.0)  # Placeholder value for the missing feature

# Ensure the new transaction has the correct number of features
if len(new_transaction) != X.shape[1]:
    raise ValueError(f"Expected {X.shape[1]} features, but got {len(new_transaction)}.")

# Convert to DataFrame with correct column names
new_transaction_df = pd.DataFrame([new_transaction], columns=X.columns)

# Scale the input
transaction_scaled = scaler.transform(new_transaction_df)

# Predict fraud status
prediction = best_model.predict(transaction_scaled)

print("Transaction Status:", "Fraudulent" if prediction[0] == 1 else "Legitimate")

